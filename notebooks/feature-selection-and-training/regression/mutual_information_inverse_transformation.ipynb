{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75973781",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import math\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler, MultiLabelBinarizer, OneHotEncoder\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import ast\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "from numpy import unique\n",
    "from scipy.stats import skew\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.ensemble import GradientBoostingRegressor \n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b574275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "TRAINING_DATA = '../../../data/preprocessed/train.parquet'\n",
    "VALIDATION_DATA = '../../../data/preprocessed/validation.parquet'\n",
    "TESTING_DATA = '../../../data/preprocessed/test.parquet'\n",
    "\n",
    "df_train = pd.read_parquet(TRAINING_DATA)\n",
    "df_validation = pd.read_parquet(VALIDATION_DATA)\n",
    "df_small_test = pd.read_parquet(TESTING_DATA)\n",
    "df_test = pd.concat([df_validation,df_small_test],axis = 0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9535cd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns\n",
    "#pd.set_option('display.max_rows', 50)\n",
    "#pd.set_option('display.max_columns', None)\n",
    "#df_train['copiesSold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c6c99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.copy()\n",
    "y_train = df_train['copiesSold'].copy()\n",
    "\n",
    "X_test = df_test.copy()\n",
    "y_test = df_test['copiesSold'].copy()\n",
    "\n",
    "X_train.drop('copiesSold',axis=1,inplace=True)\n",
    "X_test.drop('copiesSold',axis=1,inplace=True)\n",
    "X_test.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f696207",
   "metadata": {},
   "source": [
    "Function for plotting R^2,MSE,MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bbf9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_r_square(r2_scores,labelName):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, X_train.shape[1] + 1), r2_scores, marker='o', color='darkred',label=labelName)\n",
    "    plt.title(\"R² Score vs Number of Selected Features\")\n",
    "    plt.xlabel(\"Number of Top Features Selected\")\n",
    "    plt.ylabel(\"R² Score\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_mse(mse_vals,labelName):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, X_train.shape[1] + 1), mse_vals, marker='o', color='darkgreen',label=labelName)\n",
    "    plt.title(\"Mean Square Error vs Number of Selected Features\")\n",
    "    plt.xlabel(\"Number of Top Features Selected\")\n",
    "    plt.ylabel(\"MSE Score\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_mae(mae_vals,labelName):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, X_train.shape[1] + 1), mae_vals, marker='o', color='darkblue',label=labelName)\n",
    "    plt.title(\"Mean Absoulte Error vs Number of Selected Features\")\n",
    "    plt.xlabel(\"Number of Top Features Selected\")\n",
    "    plt.ylabel(\"MAE Score\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80f4403",
   "metadata": {},
   "source": [
    "Get Number of features used to get highest R^2 and lowest MAE and MSE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7295fb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(r2_scores,mse_vals,mae_vals):\n",
    "    max_r2 = max(r2_scores)\n",
    "    best_index_r2 = r2_scores.index(max_r2)\n",
    "\n",
    "    min_mse = min(mse_vals)\n",
    "    best_index_mse = mse_vals.index(min_mse)\n",
    "\n",
    "    min_mae = min(mae_vals)\n",
    "    best_index_mae = mae_vals.index(min_mae)\n",
    "    \n",
    "    print(f\"Max R² = {max_r2:.4f} at {best_index_r2 + 1} features \\nMIN MSE = {min_mse:.4f} at {best_index_mse + 1} features \\nMIN MAE = {min_mae:.4f} at {best_index_mae + 1} features \\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791f0749",
   "metadata": {},
   "source": [
    "**K best features using Mutual information feature selection method**\n",
    "\n",
    "What do mutual information scores mean?\n",
    "Each score represents how much information a feature gives about the target(output) variable.\n",
    "\n",
    "Higher score : more useful the feature is for predicting the target.\n",
    "\n",
    "Lower score (close to 0) : not informative, maybe noise or irrelevant.\n",
    "\n",
    "mutual_info_regression works with numerical and categorical features\n",
    "but It assumes numerical input only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1904371",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(columns=['name_words','has_demo','has_dlc','has_metacritic','is_release_date_known'],inplace=True)\n",
    "X_test.drop(columns=['name_words','has_demo','has_dlc','has_metacritic','is_release_date_known'],inplace=True)\n",
    "#X_train.drop(columns=['name_len','name_words','has_demo','has_dlc','has_metacritic','name_cap_ratio'],inplace=True)\n",
    "#X_test.drop(columns=['name_len','name_words','has_demo','has_dlc','has_metacritic','name_cap_ratio'],inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b299ae40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output (Target) : Numerical (Continuous) --> Regression \n",
    "# Input features : Both numerical and categorcal\n",
    "\n",
    "selector = SelectKBest(mutual_info_regression, k='all')\n",
    "selector.fit(X_train, y_train)\n",
    "\n",
    "# Get scores (information of each feature)\n",
    "mi_scores = selector.scores_\n",
    "\n",
    "# Combine feature names with scores\n",
    "feature_scores = list(zip(X_train.columns, mi_scores))\n",
    "\n",
    "# Sort by information score in descending order\n",
    "sorted_scores = sorted(feature_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for feature, score in sorted_scores:\n",
    "    print(f\"{feature}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4cc5b6",
   "metadata": {},
   "source": [
    "Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad33306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip to plot meaning we will seperate features and scores\n",
    "featuress, scores = zip(*sorted_scores)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.barh(featuress, scores, color='skyblue')\n",
    "plt.xlabel(\"Mutual Information Score\")\n",
    "plt.title(\"Feature Importance Based on Mutual Information\")\n",
    "plt.gca().invert_yaxis()  # Highest scores on top\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e12b48",
   "metadata": {},
   "source": [
    "## Gradient Boosting model\n",
    "try different number of top k features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d52e591",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_scores = []\n",
    "mse = []\n",
    "mae = []\n",
    "for i in range(1,X_train.shape[1] + 1):\n",
    "    gbr = GradientBoostingRegressor(max_depth=5,random_state=42)\n",
    "    selector = SelectKBest(mutual_info_regression,k=i)\n",
    "    selector.fit(X_train,y_train)\n",
    "\n",
    "    sel_x_train = selector.transform(X_train)\n",
    "    sel_x_test = selector.transform(X_test)\n",
    "\n",
    "    target_transformer = QuantileTransformer(output_distribution='normal',random_state=42)\n",
    "    wrapper_model = TransformedTargetRegressor(regressor=gbr,transformer=target_transformer)\n",
    "    wrapper_model.fit(sel_x_train,y_train)\n",
    "    y_pred = wrapper_model.predict(sel_x_test)\n",
    " \n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    r2_scores.append(r2)\n",
    "    mse.append(mean_squared_error(y_test,y_pred))\n",
    "    mae.append(mean_absolute_error(y_test,y_pred))\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f57ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_r_square(r2_scores,\"Gradient Boosting Regressor\")\n",
    "plot_mse(mse,\"Gradient Boosting Regressor\")\n",
    "plot_mae(mae,\"Gradient Boosting Regressor\")\n",
    "\n",
    "evaluate(r2_scores,mse,mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06103c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbf1723",
   "metadata": {},
   "source": [
    "## Decision Tree Regressor \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bc9da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_scores_ID3 = []\n",
    "mse_ID3 = []\n",
    "mae_ID3 = []\n",
    "for i in range(1,X_train.shape[1] + 1):\n",
    "    model_ID3 = DecisionTreeRegressor()\n",
    "    selector = SelectKBest(mutual_info_regression,k=i)\n",
    "    selector.fit(X_train,y_train)\n",
    "\n",
    "    sel_x_train = selector.transform(X_train)\n",
    "    sel_x_test = selector.transform(X_test)\n",
    "\n",
    "    target_transformer = QuantileTransformer(output_distribution='normal',random_state=42)\n",
    "    wrapper_model = TransformedTargetRegressor(regressor=model_ID3,transformer=target_transformer)\n",
    "    wrapper_model.fit(sel_x_train,y_train)\n",
    "    y_pred = wrapper_model.predict(sel_x_test)\n",
    "\n",
    "     \n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    r2_scores_ID3.append(r2)\n",
    "\n",
    "    mse_ID3.append(mean_squared_error(y_test,y_pred))\n",
    "    mae_ID3.append(mean_absolute_error(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b064348",
   "metadata": {},
   "source": [
    "Plotting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa31dc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_r_square(r2_scores_ID3,\"Decision Tree Regressor\")\n",
    "plot_mse(mse_ID3,\"Decision Tree Regressor\")\n",
    "plot_mae(mae_ID3,\"Decision Tree Regressor\")\n",
    "\n",
    "evaluate(r2_scores_ID3,mse_ID3,mae_ID3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c059389",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_scores_ID3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56038a0",
   "metadata": {},
   "source": [
    "Gradient Boosting variants : XGBoost, LightGBM, CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9268124",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_scores_XGBOOST = []\n",
    "r2_scores_LGBM = []\n",
    "r2_scores_CatBoost = []\n",
    "\n",
    "mse_XGBOOST = []\n",
    "mae_XGBOOST = []\n",
    "\n",
    "mse_LGBM = []\n",
    "mae_LGBM = []\n",
    "\n",
    "mse_CatBoost = []\n",
    "mae_CatBoost = []\n",
    "\n",
    "for i in range(1,X_train.shape[1] + 1):\n",
    "    model_XGB = XGBRegressor(random_state=42)\n",
    "    model_LGBM = LGBMRegressor(random_state=42)\n",
    "    model_CatBoost = CatBoostRegressor(verbose=0, random_state=42)\n",
    "\n",
    "    selector = SelectKBest(mutual_info_regression,k=i)\n",
    "    selector.fit(X_train,y_train)\n",
    "\n",
    "    sel_x_train = selector.transform(X_train)\n",
    "    sel_x_test = selector.transform(X_test)\n",
    "\n",
    "    # XGBoost\n",
    "    target_transformer = QuantileTransformer(output_distribution='normal',random_state=42)\n",
    "    wrapper_model = TransformedTargetRegressor(regressor=model_XGB,transformer=target_transformer)\n",
    "    wrapper_model.fit(sel_x_train,y_train)\n",
    "    y_pred = wrapper_model.predict(sel_x_test)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    r2_scores_XGBOOST.append(r2)\n",
    "    mse_XGBOOST.append(mean_squared_error(y_test,y_pred))\n",
    "    mae_XGBOOST.append(mean_absolute_error(y_test,y_pred))\n",
    "\n",
    "    # LightGBM\n",
    "    target_transformer = QuantileTransformer(output_distribution='normal',random_state=42)\n",
    "    wrapper_model = TransformedTargetRegressor(regressor=model_LGBM,transformer=target_transformer)\n",
    "    wrapper_model.fit(sel_x_train,y_train)\n",
    "    y_pred = wrapper_model.predict(sel_x_test)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    r2_scores_LGBM.append(r2)\n",
    "    mse_LGBM.append(mean_squared_error(y_test,y_pred))\n",
    "    mae_LGBM.append(mean_absolute_error(y_test,y_pred))\n",
    "\n",
    "    #  CatBoost\n",
    "    target_transformer = QuantileTransformer(output_distribution='normal',random_state=42)\n",
    "    wrapper_model = TransformedTargetRegressor(regressor=model_CatBoost,transformer=target_transformer)\n",
    "    wrapper_model.fit(sel_x_train,y_train)\n",
    "    y_pred = wrapper_model.predict(sel_x_test)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    r2_scores_CatBoost.append(r2)\n",
    "    mse_CatBoost.append(mean_squared_error(y_test,y_pred))\n",
    "    mae_CatBoost.append(mean_absolute_error(y_test,y_pred))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232908d8",
   "metadata": {},
   "source": [
    "Plotting for XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a200aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_r_square(r2_scores_XGBOOST,\"XGBOOST Regressor\")\n",
    "plot_mse(mse_XGBOOST,\"XGBOOST Regressor\")\n",
    "plot_mae(mae_XGBOOST,\"XGBOOST Regressor\")\n",
    "\n",
    "evaluate(r2_scores_XGBOOST,mse_XGBOOST,mae_XGBOOST)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a853a90",
   "metadata": {},
   "source": [
    "Plotting for LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3e945c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_r_square(r2_scores_LGBM,\"LightGBM Regressor\")\n",
    "plot_mse(mse_LGBM,\"LightGBM Regressor\")\n",
    "plot_mae(mae_LGBM,\"LightGBM Regressor\")\n",
    "\n",
    "evaluate(r2_scores_LGBM,mse_LGBM,mae_LGBM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2f91a1",
   "metadata": {},
   "source": [
    "Plotting for  CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b28c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_r_square(r2_scores_CatBoost,\"CatBoost Regressor\")\n",
    "plot_mse(mse_CatBoost,\"CatBoost Regressor\")\n",
    "plot_mae(mae_CatBoost,\"CatBoost Regressor\")\n",
    "\n",
    "evaluate(r2_scores_CatBoost,mse_CatBoost,mae_CatBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752c42c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_scores_CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8fa362",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_scores_linear = []\n",
    "mse_gradient_linear = []\n",
    "mae_gradient_linear = []\n",
    "for i in range(1,X_train.shape[1] + 1):\n",
    "    model_linear = LinearRegression()\n",
    "    selector = SelectKBest(mutual_info_regression,k=i)\n",
    "    selector.fit(X_train,y_train)\n",
    "\n",
    "    sel_x_train = selector.transform(X_train)\n",
    "    sel_x_test = selector.transform(X_test)\n",
    "\n",
    "    target_transformer = QuantileTransformer(output_distribution='normal',random_state=42)\n",
    "    wrapper_model = TransformedTargetRegressor(regressor=model_linear,transformer=target_transformer)\n",
    "    wrapper_model.fit(sel_x_train,y_train)\n",
    "    y_pred = wrapper_model.predict(sel_x_test)\n",
    "\n",
    "    r2 = r2_score(y_test, y_pred) \n",
    "    r2_scores_linear.append(r2)\n",
    "    mse_gradient_linear.append(mean_squared_error(y_test,y_pred))\n",
    "    mae_gradient_linear.append(mean_absolute_error(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3f639f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_r_square(r2_scores_linear,\"Linear Regression\")\n",
    "plot_mse(mse_gradient_linear,\"Linear Regression\")\n",
    "plot_mae(mae_gradient_linear,\"Linear Regression\")\n",
    "\n",
    "evaluate(r2_scores_linear,mse_gradient_linear,mae_gradient_linear)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
