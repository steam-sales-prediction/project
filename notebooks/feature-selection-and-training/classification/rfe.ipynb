{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7b73dcb",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "id": "fdf5eed5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T14:55:18.708497300Z",
     "start_time": "2025-05-14T14:55:13.354872Z"
    }
   },
   "source": [
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "import seaborn as sns"
   ],
   "outputs": [],
   "execution_count": 79
  },
  {
   "cell_type": "code",
   "id": "8e43b4d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T14:55:18.708497300Z",
     "start_time": "2025-05-14T14:55:13.402878Z"
    }
   },
   "source": [
    "PREPROCESSED_DATA_PATH = \"../../../data/preprocessed/\""
   ],
   "outputs": [],
   "execution_count": 80
  },
  {
   "cell_type": "markdown",
   "id": "e5256680",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "id": "06003879",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T14:55:18.708497300Z",
     "start_time": "2025-05-14T14:55:13.411872Z"
    }
   },
   "source": [
    "train_df = pd.read_parquet(PREPROCESSED_DATA_PATH + \"train.parquet\")\n",
    "\n",
    "val_df = pd.read_parquet(PREPROCESSED_DATA_PATH + \"validation.parquet\")\n",
    "small_test_df = pd.read_parquet(PREPROCESSED_DATA_PATH + \"test.parquet\")\n",
    "\n",
    "test_df = pd.concat([val_df, small_test_df], axis=0)"
   ],
   "outputs": [],
   "execution_count": 81
  },
  {
   "cell_type": "markdown",
   "id": "969b48f3",
   "metadata": {},
   "source": [
    "## Split Data Into Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "id": "7398b6a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T14:55:18.708497300Z",
     "start_time": "2025-05-14T14:55:13.497962Z"
    }
   },
   "source": [
    "TARGET = 'copiesSold'\n",
    "\n",
    "X_train = train_df.drop(columns=TARGET)\n",
    "y_train = train_df[TARGET]\n",
    "\n",
    "X_test = test_df.drop(columns=TARGET)\n",
    "y_test = test_df[TARGET]"
   ],
   "outputs": [],
   "execution_count": 82
  },
  {
   "cell_type": "code",
   "id": "97949cc0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T14:55:18.708497300Z",
     "start_time": "2025-05-14T14:55:13.546076Z"
    }
   },
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "X_train.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       steam_achievements  steam_trading_cards  workshop_support  \\\n",
       "index                                                              \n",
       "11655                   0                    0                 0   \n",
       "9303                    0                    0                 0   \n",
       "56618                   0                    0                 0   \n",
       "55579                   1                    0                 0   \n",
       "64439                   1                    0                 0   \n",
       "\n",
       "       achievements_total  is_release_date_known  is_upcoming  year   sin_day  \\\n",
       "index                                                                           \n",
       "11655           -0.127185                      1          0.0  2024  0.230306   \n",
       "9303            -0.127185                      1          0.0  2024 -0.060213   \n",
       "56618           -0.127185                      1          0.0  2007  0.179767   \n",
       "55579            0.105103                      1          0.0  2019 -0.188227   \n",
       "64439           -0.069113                      1          0.0  2022  0.280231   \n",
       "\n",
       "        cos_day     price  reviewScore  has_demo  demo_count  has_dlc  \\\n",
       "index                                                                   \n",
       "11655 -0.973118 -0.959158    -0.331901         0           0        0   \n",
       "9303  -0.998186 -1.631332     1.072290         0           0        0   \n",
       "56618 -0.983709 -0.061180    -0.331901         0           0        0   \n",
       "55579  0.982126 -1.631332    -0.331901         0           0        0   \n",
       "64439 -0.959933 -1.631332     1.180305         0           0        1   \n",
       "\n",
       "       dlc_count  metacritic_preprocessed  has_metacritic  genre_Action  \\\n",
       "index                                                                     \n",
       "11655          0                      0.0               0             0   \n",
       "9303           0                      0.0               0             1   \n",
       "56618          0                      0.0               0             0   \n",
       "55579          0                      0.0               0             0   \n",
       "64439          1                      0.0               0             0   \n",
       "\n",
       "       genre_Adventure  genre_Casual  genre_Early Access  genre_Free To Play  \\\n",
       "index                                                                          \n",
       "11655                0             1                   0                   0   \n",
       "9303                 1             0                   0                   1   \n",
       "56618                0             0                   0                   0   \n",
       "55579                0             0                   0                   1   \n",
       "64439                1             1                   0                   1   \n",
       "\n",
       "       genre_Gore  genre_Indie  genre_Massively Multiplayer  genre_Nudity  \\\n",
       "index                                                                       \n",
       "11655           0            0                            0             0   \n",
       "9303            0            1                            0             0   \n",
       "56618           0            0                            0             0   \n",
       "55579           0            0                            0             0   \n",
       "64439           0            1                            0             0   \n",
       "\n",
       "       genre_Other  genre_RPG  genre_Racing  genre_Sexual Content  \\\n",
       "index                                                               \n",
       "11655            0          0             0                     0   \n",
       "9303             0          1             0                     0   \n",
       "56618            0          0             1                     0   \n",
       "55579            0          0             0                     0   \n",
       "64439            0          0             0                     0   \n",
       "\n",
       "       genre_Simulation  genre_Sports  genre_Strategy  genre_Violent  \\\n",
       "index                                                                  \n",
       "11655                 0             0               0              0   \n",
       "9303                  0             0               0              0   \n",
       "56618                 0             0               0              0   \n",
       "55579                 1             0               0              0   \n",
       "64439                 0             0               0              0   \n",
       "\n",
       "       platform_linux  platform_mac  platform_windows  name_len  name_words  \\\n",
       "index                                                                         \n",
       "11655               0             0                 1 -0.129008   -0.485228   \n",
       "9303                0             0                 1 -0.430898    0.109341   \n",
       "56618               0             0                 1  0.575401    0.109341   \n",
       "55579               0             0                 1 -0.129008    0.703911   \n",
       "64439               1             1                 1 -0.833418   -1.079798   \n",
       "\n",
       "       name_cap_ratio  is_sequel  name_has_vr  name_has_remaster  \\\n",
       "index                                                              \n",
       "11655       -0.422150  -0.241008    -0.141551          -0.018005   \n",
       "9303         0.140908  -0.241008    -0.141551          -0.018005   \n",
       "56618        0.301146  -0.241008    -0.141551          -0.018005   \n",
       "55579        0.243282  -0.241008     7.064584          -0.018005   \n",
       "64439       -0.496087  -0.241008    -0.141551          -0.018005   \n",
       "\n",
       "       name_has_collector  name_has_collection  name_has_edition  \\\n",
       "index                                                              \n",
       "11655           -0.025111            -0.045946         -0.125187   \n",
       "9303            -0.025111            -0.045946         -0.125187   \n",
       "56618           -0.025111            -0.045946         -0.125187   \n",
       "55579           -0.025111            -0.045946         -0.125187   \n",
       "64439           -0.025111            -0.045946         -0.125187   \n",
       "\n",
       "       name_has_bundle  name_has_playtest  publisherClass_Indie  \\\n",
       "index                                                             \n",
       "11655        -0.012731                0.0                   0.0   \n",
       "9303         -0.012731                0.0                   0.0   \n",
       "56618        -0.012731                0.0                   1.0   \n",
       "55579        -0.012731                0.0                   1.0   \n",
       "64439        -0.012731                0.0                   0.0   \n",
       "\n",
       "       publisherClass_Other  \n",
       "index                        \n",
       "11655                   0.0  \n",
       "9303                    0.0  \n",
       "56618                   0.0  \n",
       "55579                   0.0  \n",
       "64439                   0.0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>steam_achievements</th>\n",
       "      <th>steam_trading_cards</th>\n",
       "      <th>workshop_support</th>\n",
       "      <th>achievements_total</th>\n",
       "      <th>is_release_date_known</th>\n",
       "      <th>is_upcoming</th>\n",
       "      <th>year</th>\n",
       "      <th>sin_day</th>\n",
       "      <th>cos_day</th>\n",
       "      <th>price</th>\n",
       "      <th>reviewScore</th>\n",
       "      <th>has_demo</th>\n",
       "      <th>demo_count</th>\n",
       "      <th>has_dlc</th>\n",
       "      <th>dlc_count</th>\n",
       "      <th>metacritic_preprocessed</th>\n",
       "      <th>has_metacritic</th>\n",
       "      <th>genre_Action</th>\n",
       "      <th>genre_Adventure</th>\n",
       "      <th>genre_Casual</th>\n",
       "      <th>genre_Early Access</th>\n",
       "      <th>genre_Free To Play</th>\n",
       "      <th>genre_Gore</th>\n",
       "      <th>genre_Indie</th>\n",
       "      <th>genre_Massively Multiplayer</th>\n",
       "      <th>genre_Nudity</th>\n",
       "      <th>genre_Other</th>\n",
       "      <th>genre_RPG</th>\n",
       "      <th>genre_Racing</th>\n",
       "      <th>genre_Sexual Content</th>\n",
       "      <th>genre_Simulation</th>\n",
       "      <th>genre_Sports</th>\n",
       "      <th>genre_Strategy</th>\n",
       "      <th>genre_Violent</th>\n",
       "      <th>platform_linux</th>\n",
       "      <th>platform_mac</th>\n",
       "      <th>platform_windows</th>\n",
       "      <th>name_len</th>\n",
       "      <th>name_words</th>\n",
       "      <th>name_cap_ratio</th>\n",
       "      <th>is_sequel</th>\n",
       "      <th>name_has_vr</th>\n",
       "      <th>name_has_remaster</th>\n",
       "      <th>name_has_collector</th>\n",
       "      <th>name_has_collection</th>\n",
       "      <th>name_has_edition</th>\n",
       "      <th>name_has_bundle</th>\n",
       "      <th>name_has_playtest</th>\n",
       "      <th>publisherClass_Indie</th>\n",
       "      <th>publisherClass_Other</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11655</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.127185</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024</td>\n",
       "      <td>0.230306</td>\n",
       "      <td>-0.973118</td>\n",
       "      <td>-0.959158</td>\n",
       "      <td>-0.331901</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.129008</td>\n",
       "      <td>-0.485228</td>\n",
       "      <td>-0.422150</td>\n",
       "      <td>-0.241008</td>\n",
       "      <td>-0.141551</td>\n",
       "      <td>-0.018005</td>\n",
       "      <td>-0.025111</td>\n",
       "      <td>-0.045946</td>\n",
       "      <td>-0.125187</td>\n",
       "      <td>-0.012731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9303</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.127185</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024</td>\n",
       "      <td>-0.060213</td>\n",
       "      <td>-0.998186</td>\n",
       "      <td>-1.631332</td>\n",
       "      <td>1.072290</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.430898</td>\n",
       "      <td>0.109341</td>\n",
       "      <td>0.140908</td>\n",
       "      <td>-0.241008</td>\n",
       "      <td>-0.141551</td>\n",
       "      <td>-0.018005</td>\n",
       "      <td>-0.025111</td>\n",
       "      <td>-0.045946</td>\n",
       "      <td>-0.125187</td>\n",
       "      <td>-0.012731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56618</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.127185</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2007</td>\n",
       "      <td>0.179767</td>\n",
       "      <td>-0.983709</td>\n",
       "      <td>-0.061180</td>\n",
       "      <td>-0.331901</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575401</td>\n",
       "      <td>0.109341</td>\n",
       "      <td>0.301146</td>\n",
       "      <td>-0.241008</td>\n",
       "      <td>-0.141551</td>\n",
       "      <td>-0.018005</td>\n",
       "      <td>-0.025111</td>\n",
       "      <td>-0.045946</td>\n",
       "      <td>-0.125187</td>\n",
       "      <td>-0.012731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55579</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.105103</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>-0.188227</td>\n",
       "      <td>0.982126</td>\n",
       "      <td>-1.631332</td>\n",
       "      <td>-0.331901</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.129008</td>\n",
       "      <td>0.703911</td>\n",
       "      <td>0.243282</td>\n",
       "      <td>-0.241008</td>\n",
       "      <td>7.064584</td>\n",
       "      <td>-0.018005</td>\n",
       "      <td>-0.025111</td>\n",
       "      <td>-0.045946</td>\n",
       "      <td>-0.125187</td>\n",
       "      <td>-0.012731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64439</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.069113</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.280231</td>\n",
       "      <td>-0.959933</td>\n",
       "      <td>-1.631332</td>\n",
       "      <td>1.180305</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.833418</td>\n",
       "      <td>-1.079798</td>\n",
       "      <td>-0.496087</td>\n",
       "      <td>-0.241008</td>\n",
       "      <td>-0.141551</td>\n",
       "      <td>-0.018005</td>\n",
       "      <td>-0.025111</td>\n",
       "      <td>-0.045946</td>\n",
       "      <td>-0.125187</td>\n",
       "      <td>-0.012731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 83
  },
  {
   "cell_type": "code",
   "id": "7e1831b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T14:55:18.708497300Z",
     "start_time": "2025-05-14T14:55:13.626380Z"
    }
   },
   "source": [
    "y_train.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index\n",
       "11655    0\n",
       "9303     0\n",
       "56618    0\n",
       "55579    1\n",
       "64439    1\n",
       "Name: copiesSold, dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 84
  },
  {
   "cell_type": "markdown",
   "id": "ab93047a",
   "metadata": {},
   "source": [
    "## Define Models and Hyperparameter Grids"
   ]
  },
  {
   "cell_type": "code",
   "id": "681a7ff9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T14:55:18.724126700Z",
     "start_time": "2025-05-14T14:55:13.701290Z"
    }
   },
   "source": [
    "# models = {\n",
    "#     'LogisticRegression': {\n",
    "#         'get_model': lambda param: LogisticRegression(C=param, max_iter=1000, solver='liblinear'),\n",
    "#         'param_name': 'C',\n",
    "#         'param_values': [1]\n",
    "#     },\n",
    "#     'LinearSVC': {\n",
    "#         'get_model': lambda param: LinearSVC(C=param, max_iter=10000),\n",
    "#         'param_name': 'C',\n",
    "#         'param_values': [0.1, 1, 10]\n",
    "#     },\n",
    "#     'XGBoost': {\n",
    "#         'get_model': lambda param: XGBClassifier(learning_rate=param, eval_metric='logloss', n_jobs=-1),\n",
    "#         'param_name': 'learning_rate',\n",
    "#         'param_values': [0.1, 0.2, 0.3]\n",
    "#     }\n",
    "# }"
   ],
   "outputs": [],
   "execution_count": 85
  },
  {
   "cell_type": "markdown",
   "id": "07c6d4e8",
   "metadata": {},
   "source": [
    "## Feature Selection and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "id": "a35cff30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T14:55:18.724126700Z",
     "start_time": "2025-05-14T14:55:13.797078Z"
    }
   },
   "source": [
    "# best_params = {}\n",
    "# best_selectors = {}\n",
    "#\n",
    "# for model_name, info in models.items():\n",
    "#     scores = []\n",
    "#     for val in info['param_values']:\n",
    "#         model = info['get_model'](val)\n",
    "#         # Feature Selection, RFECV automatically finds the best number of features\n",
    "#         print(f\"\\nRunning RFECV for {model_name}...\")\n",
    "#         selector = RFECV(estimator=model, cv=3, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "#         X_sel = selector.fit_transform(X_train, y_train)\n",
    "#         # Evaluate performance on selected features with the current hyperparameter\n",
    "#         print(f\"\\nRunning CV for {model_name}...\")\n",
    "#         cv_scores = cross_val_score(model, X_sel, y_train, cv=3, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "#         scores.append(np.mean(cv_scores))\n",
    "#\n",
    "#     # Plot hyperparameter tuning curve\n",
    "#     plt.figure()\n",
    "#     plt.plot(info['param_values'], scores, marker='o')\n",
    "#     plt.xlabel(info['param_name'])\n",
    "#     plt.ylabel('CV Accuracy')\n",
    "#     plt.title(f'{model_name} Hyperparameter Tuning')\n",
    "#     plt.show()\n",
    "#\n",
    "#     # Record best hyperparameter and corresponding RFECV selector (which contains the best features selected for this model)\n",
    "#     best_index = int(np.argmax(scores))\n",
    "#     best_param = info['param_values'][best_index]\n",
    "#     best_params[model_name] = best_param\n",
    "#     best_model = info['get_model'](best_param)\n",
    "#     best_selectors[model_name] = RFECV(estimator=best_model, cv=3, scoring='accuracy')\n",
    "#     best_selectors[model_name].fit(X_train, y_train)"
   ],
   "outputs": [],
   "execution_count": 86
  },
  {
   "cell_type": "markdown",
   "id": "e208d500",
   "metadata": {},
   "source": [
    "## Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "id": "397fda8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T14:55:18.724126700Z",
     "start_time": "2025-05-14T14:55:13.950926Z"
    }
   },
   "source": [
    "# # Train final models and collect metrics\n",
    "# train_times = {}\n",
    "# test_times = {}\n",
    "# accuracies = {}\n",
    "#\n",
    "# for model_name, info in models.items():\n",
    "#     selector = best_selectors[model_name]\n",
    "#     X_train_sel = selector.transform(X_train)\n",
    "#     X_test_sel = selector.transform(X_test)\n",
    "#     model = info['get_model'](best_params[model_name])\n",
    "#\n",
    "#     # Training\n",
    "#     start = time.time()\n",
    "#     model.fit(X_train_sel, y_train)\n",
    "#     train_times[model_name] = time.time() - start\n",
    "#\n",
    "#     # Testing\n",
    "#     start = time.time()\n",
    "#     y_pred = model.predict(X_test_sel)\n",
    "#     test_times[model_name] = time.time() - start\n",
    "#\n",
    "#     # Accuracy\n",
    "#     accuracies[model_name] = accuracy_score(y_test, y_pred)\n",
    "#\n",
    "# # Bar plot: Test Accuracy\n",
    "# print(list(accuracies.keys()))\n",
    "# print(list(round(accuracy, 3) for accuracy in accuracies.values()))\n",
    "# plt.figure()\n",
    "# plt.bar(list(accuracies.keys()), list(accuracies.values()))\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.title('Test Accuracy Comparison')\n",
    "# plt.show()\n",
    "#\n",
    "# # Bar plot: Training Time\n",
    "# plt.figure()\n",
    "# plt.bar(list(train_times.keys()), list(train_times.values()))\n",
    "# plt.ylabel('Training Time (s)')\n",
    "# plt.title('Training Time Comparison')\n",
    "# plt.show()\n",
    "#\n",
    "# # Bar plot: Testing Time\n",
    "# plt.figure()\n",
    "# plt.bar(list(test_times.keys()), list(test_times.values()))\n",
    "# plt.ylabel('Testing Time (s)')\n",
    "# plt.title('Testing Time Comparison')\n",
    "# plt.show()"
   ],
   "outputs": [],
   "execution_count": 87
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T14:55:18.724126700Z",
     "start_time": "2025-05-14T14:55:14.010083Z"
    }
   },
   "cell_type": "code",
   "source": [
    "models = {\n",
    "    'LogisticRegression': {\n",
    "        'class': LogisticRegression,\n",
    "        'params': {\n",
    "            'C': [0.01, 0.1, 1],\n",
    "            # 'penalty': ['l1', 'l2'],\n",
    "            'solver': ['liblinear', 'lbfgs', 'saga'],\n",
    "            'fixed': {\n",
    "                # 'solver': 'liblinear',\n",
    "                'penalty': 'l2',\n",
    "                'max_iter': 5000,\n",
    "                'class_weight': 'balanced',\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'SVC': {\n",
    "        'class': SVC,\n",
    "        'params': {\n",
    "            'C': [0.1, 1.0, 10],\n",
    "            'kernel': ['linear', 'rbf', 'poly'],\n",
    "            'degree': [2, 3, 4],                    # Polynomial degree (active when kernel = 'poly')\n",
    "            'fixed': {\n",
    "                'max_iter': 10000,\n",
    "                'probability': True,\n",
    "                'class_weight': 'balanced'\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'class': XGBClassifier,\n",
    "        'params': {\n",
    "            'learning_rate': [0.01, 0.05, 0.1],\n",
    "            'max_depth': [3, 5, 7],\n",
    "            'fixed': {\n",
    "                'eval_metric': 'mlogloss',\n",
    "                'use_label_encoder': False,\n",
    "                'n_jobs': -1\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ],
   "id": "4b3bbb7bc82ef15d",
   "outputs": [],
   "execution_count": 88
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T14:55:18.704534Z",
     "start_time": "2025-05-14T14:55:14.036200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "best_params = {}\n",
    "best_selectors = {}\n",
    "best_scores = {}\n",
    "param_plot_data = {model: {} for model in models}\n",
    "\n",
    "for model_name, config in models.items():\n",
    "    print(f\"\\n=== Tuning {model_name} ===\")\n",
    "    model_class = config['class']\n",
    "    fixed_params = config['params'].get('fixed', {})\n",
    "\n",
    "    for param_name, param_values in config['params'].items():\n",
    "        if param_name == 'fixed':\n",
    "            continue\n",
    "\n",
    "        # Skip degree for now â€” handle after kernel is selected\n",
    "        if model_name == 'SVC' and param_name == 'degree':\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nTuning {param_name}...\")\n",
    "        param_scores = []\n",
    "\n",
    "        for value in param_values:\n",
    "            print(f\"  Testing {param_name} = {value}\")\n",
    "            model_args = {**fixed_params, param_name: value}\n",
    "            model = model_class(**model_args)\n",
    "\n",
    "            selector = RFECV(model, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "            X_sel = selector.fit_transform(X_train, y_train)\n",
    "\n",
    "            score = cross_val_score(\n",
    "                model, X_sel, y_train,\n",
    "                cv=3, scoring='accuracy', n_jobs=-1\n",
    "            ).mean()\n",
    "\n",
    "            param_scores.append(score)\n",
    "            print(f\"    Score: {score:.4f}\")\n",
    "\n",
    "        # Save for plotting\n",
    "        param_plot_data[model_name][param_name] = {\n",
    "            'values': param_values,\n",
    "            'scores': param_scores\n",
    "        }\n",
    "\n",
    "        # Store best\n",
    "        best_idx = np.argmax(param_scores)\n",
    "        best_val = param_values[best_idx]\n",
    "        best_params[f\"{model_name}_{param_name}\"] = best_val\n",
    "        best_scores[f\"{model_name}_{param_name}\"] = param_scores[best_idx]\n",
    "\n",
    "        final_model = model_class(**{**fixed_params, param_name: best_val})\n",
    "        best_selector = RFECV(final_model, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "        best_selector.fit(X_train, y_train)\n",
    "        best_selectors[model_name] = best_selector\n",
    "\n",
    "    # Special case: if SVC and best kernel is poly, tune degree now\n",
    "    if model_name == 'SVC' and best_params.get('SVC_kernel') == 'poly':\n",
    "        print(f\"\\nTuning degree for {model_name} since kernel='poly'\")\n",
    "        degree_scores = []\n",
    "        degree_values = config['params']['degree']\n",
    "\n",
    "        for deg in degree_values:\n",
    "            print(f\"  Testing degree = {deg}\")\n",
    "            model_args = {\n",
    "                **fixed_params,\n",
    "                'kernel': 'poly',\n",
    "                'degree': deg,\n",
    "                'C': best_params['SVC_C']  # use best C found\n",
    "            }\n",
    "            model = model_class(**model_args)\n",
    "\n",
    "            selector = RFECV(model, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "            X_sel = selector.fit_transform(X_train, y_train)\n",
    "\n",
    "            score = cross_val_score(\n",
    "                model, X_sel, y_train,\n",
    "                cv=3, scoring='accuracy', n_jobs=-1\n",
    "            ).mean()\n",
    "\n",
    "            degree_scores.append(score)\n",
    "            print(f\"    Score: {score:.4f}\")\n",
    "\n",
    "        # Save for plotting\n",
    "        param_plot_data[model_name]['degree'] = {\n",
    "            'values': degree_values,\n",
    "            'scores': degree_scores\n",
    "        }\n",
    "\n",
    "        # Save best degree\n",
    "        best_idx = np.argmax(degree_scores)\n",
    "        best_val = degree_values[best_idx]\n",
    "        best_params[f\"{model_name}_degree\"] = best_val\n",
    "        best_scores[f\"{model_name}_degree\"] = degree_scores[best_idx]\n",
    "\n",
    "        final_model = model_class(**{\n",
    "            **fixed_params,\n",
    "            'kernel': 'poly',\n",
    "            'degree': best_val,\n",
    "            'C': best_params['SVC_C']\n",
    "        })\n",
    "        best_selector = RFECV(final_model, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "        best_selector.fit(X_train, y_train)\n",
    "        best_selectors[model_name] = best_selector"
   ],
   "id": "ef9db8f362a79864",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Tuning LogisticRegression ===\n",
      "\n",
      "Tuning C...\n",
      "  Testing C = 0.01\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[89]\u001B[39m\u001B[32m, line 28\u001B[39m\n\u001B[32m     25\u001B[39m model = model_class(**model_args)\n\u001B[32m     27\u001B[39m selector = RFECV(model, cv=\u001B[32m3\u001B[39m, scoring=\u001B[33m'\u001B[39m\u001B[33maccuracy\u001B[39m\u001B[33m'\u001B[39m, n_jobs=-\u001B[32m1\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m28\u001B[39m X_sel = \u001B[43mselector\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfit_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     30\u001B[39m score = cross_val_score(\n\u001B[32m     31\u001B[39m     model, X_sel, y_train,\n\u001B[32m     32\u001B[39m     cv=\u001B[32m3\u001B[39m, scoring=\u001B[33m'\u001B[39m\u001B[33maccuracy\u001B[39m\u001B[33m'\u001B[39m, n_jobs=-\u001B[32m1\u001B[39m\n\u001B[32m     33\u001B[39m ).mean()\n\u001B[32m     35\u001B[39m param_scores.append(score)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:319\u001B[39m, in \u001B[36m_wrap_method_output.<locals>.wrapped\u001B[39m\u001B[34m(self, X, *args, **kwargs)\u001B[39m\n\u001B[32m    317\u001B[39m \u001B[38;5;129m@wraps\u001B[39m(f)\n\u001B[32m    318\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mwrapped\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, *args, **kwargs):\n\u001B[32m--> \u001B[39m\u001B[32m319\u001B[39m     data_to_wrap = \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    320\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_to_wrap, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[32m    321\u001B[39m         \u001B[38;5;66;03m# only wrap the first output for cross decomposition\u001B[39;00m\n\u001B[32m    322\u001B[39m         return_tuple = (\n\u001B[32m    323\u001B[39m             _wrap_data_with_container(method, data_to_wrap[\u001B[32m0\u001B[39m], X, \u001B[38;5;28mself\u001B[39m),\n\u001B[32m    324\u001B[39m             *data_to_wrap[\u001B[32m1\u001B[39m:],\n\u001B[32m    325\u001B[39m         )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\sklearn\\base.py:921\u001B[39m, in \u001B[36mTransformerMixin.fit_transform\u001B[39m\u001B[34m(self, X, y, **fit_params)\u001B[39m\n\u001B[32m    918\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.fit(X, **fit_params).transform(X)\n\u001B[32m    919\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    920\u001B[39m     \u001B[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m921\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mfit_params\u001B[49m\u001B[43m)\u001B[49m.transform(X)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:63\u001B[39m, in \u001B[36m_deprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m     61\u001B[39m extra_args = \u001B[38;5;28mlen\u001B[39m(args) - \u001B[38;5;28mlen\u001B[39m(all_args)\n\u001B[32m     62\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m extra_args <= \u001B[32m0\u001B[39m:\n\u001B[32m---> \u001B[39m\u001B[32m63\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     65\u001B[39m \u001B[38;5;66;03m# extra_args > 0\u001B[39;00m\n\u001B[32m     66\u001B[39m args_msg = [\n\u001B[32m     67\u001B[39m     \u001B[33m\"\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[33m=\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[33m\"\u001B[39m.format(name, arg)\n\u001B[32m     68\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m name, arg \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(kwonly_args[:extra_args], args[-extra_args:])\n\u001B[32m     69\u001B[39m ]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\sklearn\\base.py:1389\u001B[39m, in \u001B[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[39m\u001B[34m(estimator, *args, **kwargs)\u001B[39m\n\u001B[32m   1382\u001B[39m     estimator._validate_params()\n\u001B[32m   1384\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[32m   1385\u001B[39m     skip_parameter_validation=(\n\u001B[32m   1386\u001B[39m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[32m   1387\u001B[39m     )\n\u001B[32m   1388\u001B[39m ):\n\u001B[32m-> \u001B[39m\u001B[32m1389\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:873\u001B[39m, in \u001B[36mRFECV.fit\u001B[39m\u001B[34m(self, X, y, groups, **params)\u001B[39m\n\u001B[32m    870\u001B[39m     parallel = Parallel(n_jobs=\u001B[38;5;28mself\u001B[39m.n_jobs)\n\u001B[32m    871\u001B[39m     func = delayed(_rfe_single_fit)\n\u001B[32m--> \u001B[39m\u001B[32m873\u001B[39m scores_features = \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    874\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrfe\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscorer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrouted_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    875\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mcv\u001B[49m\u001B[43m.\u001B[49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mrouted_params\u001B[49m\u001B[43m.\u001B[49m\u001B[43msplitter\u001B[49m\u001B[43m.\u001B[49m\u001B[43msplit\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    876\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    877\u001B[39m scores, step_n_features = \u001B[38;5;28mzip\u001B[39m(*scores_features)\n\u001B[32m    879\u001B[39m step_n_features_rev = np.array(step_n_features[\u001B[32m0\u001B[39m])[::-\u001B[32m1\u001B[39m]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001B[39m, in \u001B[36mParallel.__call__\u001B[39m\u001B[34m(self, iterable)\u001B[39m\n\u001B[32m     72\u001B[39m config = get_config()\n\u001B[32m     73\u001B[39m iterable_with_config = (\n\u001B[32m     74\u001B[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[32m     75\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[32m     76\u001B[39m )\n\u001B[32m---> \u001B[39m\u001B[32m77\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[34;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\joblib\\parallel.py:2007\u001B[39m, in \u001B[36mParallel.__call__\u001B[39m\u001B[34m(self, iterable)\u001B[39m\n\u001B[32m   2001\u001B[39m \u001B[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001B[39;00m\n\u001B[32m   2002\u001B[39m \u001B[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001B[39;00m\n\u001B[32m   2003\u001B[39m \u001B[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001B[39;00m\n\u001B[32m   2004\u001B[39m \u001B[38;5;66;03m# dispatch of the tasks to the workers.\u001B[39;00m\n\u001B[32m   2005\u001B[39m \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[32m-> \u001B[39m\u001B[32m2007\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.return_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1650\u001B[39m, in \u001B[36mParallel._get_outputs\u001B[39m\u001B[34m(self, iterator, pre_dispatch)\u001B[39m\n\u001B[32m   1647\u001B[39m     \u001B[38;5;28;01myield\u001B[39;00m\n\u001B[32m   1649\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backend.retrieval_context():\n\u001B[32m-> \u001B[39m\u001B[32m1650\u001B[39m         \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m._retrieve()\n\u001B[32m   1652\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mGeneratorExit\u001B[39;00m:\n\u001B[32m   1653\u001B[39m     \u001B[38;5;66;03m# The generator has been garbage collected before being fully\u001B[39;00m\n\u001B[32m   1654\u001B[39m     \u001B[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001B[39;00m\n\u001B[32m   1655\u001B[39m     \u001B[38;5;66;03m# the user if necessary.\u001B[39;00m\n\u001B[32m   1656\u001B[39m     \u001B[38;5;28mself\u001B[39m._exception = \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1762\u001B[39m, in \u001B[36mParallel._retrieve\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# async callbacks to progress.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m ((\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m._jobs) == \u001B[32m0\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m\n\u001B[32m   1760\u001B[39m     (\u001B[38;5;28mself\u001B[39m._jobs[\u001B[32m0\u001B[39m].get_status(\n\u001B[32m   1761\u001B[39m         timeout=\u001B[38;5;28mself\u001B[39m.timeout) == TASK_PENDING)):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[43mtime\u001B[49m\u001B[43m.\u001B[49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[32;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m   1763\u001B[39m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[32m   1765\u001B[39m \u001B[38;5;66;03m# We need to be careful: the job list can be filling up as\u001B[39;00m\n\u001B[32m   1766\u001B[39m \u001B[38;5;66;03m# we empty it and Python list are not thread-safe by\u001B[39;00m\n\u001B[32m   1767\u001B[39m \u001B[38;5;66;03m# default hence the use of the lock\u001B[39;00m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 89
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Summary\n",
    "print(\"\\n=== Best Parameters ===\")\n",
    "for param, val in best_params.items():\n",
    "    print(f\"{param}: {val} (score: {best_scores.get(param, 'N/A'):.4f})\")\n",
    "\n",
    "# Plotting\n",
    "print(\"\\n=== Plotting Accuracy vs Hyperparameter ===\")\n",
    "for model_name, param_data in param_plot_data.items():\n",
    "    for param_name, data in param_data.items():\n",
    "        plt.figure(figsize=(8, 5))\n",
    "\n",
    "        if isinstance(data['values'][0], str):\n",
    "            sns.barplot(x=data['values'], y=data['scores'])\n",
    "        else:\n",
    "            sns.lineplot(x=data['values'], y=data['scores'], marker='o')\n",
    "\n",
    "        plt.title(f\"{model_name}: Accuracy vs {param_name}\")\n",
    "        plt.xlabel(param_name)\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ],
   "id": "6a91d1ccf60f387a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "train_times = {}\n",
    "test_times = {}\n",
    "accuracies = {}\n",
    "\n",
    "for model_name, info in models.items():\n",
    "    selector = best_selectors[model_name]\n",
    "    X_train_sel = selector.transform(X_train)\n",
    "    X_test_sel = selector.transform(X_test)\n",
    "\n",
    "    # Reconstruct best parameters\n",
    "    model_class = info['class']\n",
    "    model_args = {**info['params'].get('fixed', {})}\n",
    "\n",
    "    for key, val in best_params.items():\n",
    "        if key.startswith(model_name + \"_\"):\n",
    "            param_name = key.replace(model_name + \"_\", \"\")\n",
    "            model_args[param_name] = val\n",
    "\n",
    "    # Enable probabilities for SVM\n",
    "    if model_name == \"SVC\":\n",
    "        model_args[\"probability\"] = True\n",
    "\n",
    "    model = model_class(**model_args)\n",
    "\n",
    "    # Train\n",
    "    start = time.time()\n",
    "    model.fit(X_train_sel, y_train)\n",
    "    train_times[model_name] = time.time() - start\n",
    "\n",
    "    # Predict\n",
    "    start = time.time()\n",
    "\n",
    "    if model_name == \"SVC\":\n",
    "        y_proba = model.predict_proba(X_test_sel)\n",
    "        y_pred = np.argmax(y_proba, axis=1)\n",
    "    else:\n",
    "        y_pred = model.predict(X_test_sel)\n",
    "\n",
    "    test_times[model_name] = time.time() - start\n",
    "\n",
    "    # Accuracy\n",
    "    accuracies[model_name] = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Plot Accuracy\n",
    "plt.figure()\n",
    "plt.bar(list(accuracies.keys()), list(accuracies.values()))\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Test Accuracy Comparison')\n",
    "plt.show()\n",
    "\n",
    "# Plot Training Time\n",
    "plt.figure()\n",
    "plt.bar(list(train_times.keys()), list(train_times.values()))\n",
    "plt.ylabel('Training Time (s)')\n",
    "plt.title('Training Time Comparison')\n",
    "plt.show()\n",
    "\n",
    "# Plot Testing Time\n",
    "plt.figure()\n",
    "plt.bar(list(test_times.keys()), list(test_times.values()))\n",
    "plt.ylabel('Testing Time (s)')\n",
    "plt.title('Testing Time Comparison')\n",
    "plt.show()\n"
   ],
   "id": "c31af2ca0bb358fe"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
