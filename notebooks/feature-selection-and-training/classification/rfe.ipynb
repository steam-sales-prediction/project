{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7b73dcb",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf5eed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e43b4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREPROCESSED_DATA_PATH = \"../../../data/preprocessed/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5256680",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06003879",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet(PREPROCESSED_DATA_PATH + \"train.parquet\")\n",
    "\n",
    "val_df = pd.read_parquet(PREPROCESSED_DATA_PATH + \"validation.parquet\")\n",
    "small_test_df = pd.read_parquet(PREPROCESSED_DATA_PATH + \"test.parquet\")\n",
    "\n",
    "test_df = pd.concat([val_df, small_test_df], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969b48f3",
   "metadata": {},
   "source": [
    "## Split Data Into Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7398b6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'copiesSold'\n",
    "\n",
    "X_train = train_df.drop(columns=TARGET)\n",
    "y_train = train_df[TARGET]\n",
    "\n",
    "X_test = test_df.drop(columns=TARGET)\n",
    "y_test = test_df[TARGET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97949cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1831b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab93047a",
   "metadata": {},
   "source": [
    "## Define Models and Hyperparameter Grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681a7ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'LogisticRegression': {\n",
    "        'get_model': lambda param: LogisticRegression(C=param, max_iter=1000, solver='liblinear'),\n",
    "        'param_name': 'C',\n",
    "        'param_values': [1]\n",
    "    },\n",
    "    'LinearSVC': {\n",
    "        'get_model': lambda param: LinearSVC(C=param, max_iter=10000),\n",
    "        'param_name': 'C',\n",
    "        'param_values': [0.1, 1, 10]\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'get_model': lambda param: XGBClassifier(learning_rate=param, eval_metric='logloss', n_jobs=-1),\n",
    "        'param_name': 'learning_rate',\n",
    "        'param_values': [0.1, 0.2, 0.3]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c6d4e8",
   "metadata": {},
   "source": [
    "## Feature Selection and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35cff30",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {}\n",
    "best_selectors = {}\n",
    "\n",
    "for model_name, info in models.items():\n",
    "    scores = []\n",
    "    for val in info['param_values']:\n",
    "        model = info['get_model'](val)\n",
    "        # Feature Selection, RFECV automatically finds the best number of features\n",
    "        print(f\"\\nRunning RFECV for {model_name}...\")\n",
    "        selector = RFECV(estimator=model, cv=3, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "        X_sel = selector.fit_transform(X_train, y_train)\n",
    "        # Evaluate performance on selected features with the current hyperparameter\n",
    "        print(f\"\\nRunning CV for {model_name}...\")\n",
    "        cv_scores = cross_val_score(model, X_sel, y_train, cv=3, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "        scores.append(np.mean(cv_scores))\n",
    "\n",
    "    # Plot hyperparameter tuning curve\n",
    "    plt.figure()\n",
    "    plt.plot(info['param_values'], scores, marker='o')\n",
    "    plt.xlabel(info['param_name'])\n",
    "    plt.ylabel('CV Accuracy')\n",
    "    plt.title(f'{model_name} Hyperparameter Tuning')\n",
    "    plt.show()\n",
    "\n",
    "    # Record best hyperparameter and corresponding RFECV selector (which contains the best features selected for this model)\n",
    "    best_index = int(np.argmax(scores))\n",
    "    best_param = info['param_values'][best_index]\n",
    "    best_params[model_name] = best_param\n",
    "    best_model = info['get_model'](best_param)\n",
    "    best_selectors[model_name] = RFECV(estimator=best_model, cv=3, scoring='accuracy')\n",
    "    best_selectors[model_name].fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e208d500",
   "metadata": {},
   "source": [
    "## Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397fda8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final models and collect metrics\n",
    "train_times = {}\n",
    "test_times = {}\n",
    "accuracies = {}\n",
    "\n",
    "for model_name, info in models.items():\n",
    "    selector = best_selectors[model_name]\n",
    "    X_train_sel = selector.transform(X_train)\n",
    "    X_test_sel = selector.transform(X_test)\n",
    "    model = info['get_model'](best_params[model_name])\n",
    "\n",
    "    # Training\n",
    "    start = time.time()\n",
    "    model.fit(X_train_sel, y_train)\n",
    "    train_times[model_name] = time.time() - start\n",
    "\n",
    "    # Testing\n",
    "    start = time.time()\n",
    "    y_pred = model.predict(X_test_sel)\n",
    "    test_times[model_name] = time.time() - start\n",
    "\n",
    "    # Accuracy\n",
    "    accuracies[model_name] = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Bar plot: Test Accuracy\n",
    "plt.figure()\n",
    "plt.bar(list(accuracies.keys()), list(accuracies.values()))\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Test Accuracy Comparison')\n",
    "plt.show()\n",
    "\n",
    "# Bar plot: Training Time\n",
    "plt.figure()\n",
    "plt.bar(list(train_times.keys()), list(train_times.values()))\n",
    "plt.ylabel('Training Time (s)')\n",
    "plt.title('Training Time Comparison')\n",
    "plt.show()\n",
    "\n",
    "# Bar plot: Testing Time\n",
    "plt.figure()\n",
    "plt.bar(list(test_times.keys()), list(test_times.values()))\n",
    "plt.ylabel('Testing Time (s)')\n",
    "plt.title('Testing Time Comparison')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
